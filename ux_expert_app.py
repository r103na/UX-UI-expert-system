import streamlit as st
from PIL import Image
import numpy as np
import pytesseract
from sklearn.cluster import KMeans
import cv2

# ========== –¢–µ–∫—Å—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π ==========
def preprocess_image_for_ocr(img):
    img_array = np.array(img)

    # –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
    alpha = 2.5
    beta = 0
    contrast_img = cv2.convertScaleAbs(img_array, alpha=alpha, beta=beta)

    gray = cv2.cvtColor(contrast_img, cv2.COLOR_BGR2GRAY)

    new_image = Image.fromarray(gray)
    return new_image


def perform_ocr_analysis(image: Image.Image):
    custom_config = r'--oem 3 --psm 4'
    min_text_length = 1

    new_image = preprocess_image_for_ocr(image)
    data = pytesseract.image_to_data(new_image, config=custom_config, output_type=pytesseract.Output.DICT)

    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è: —É–¥–∞–ª—è–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ —Å —Ç–µ–∫—Å—Ç–æ–º –¥–ª–∏–Ω–æ–π 1 –∏–ª–∏ –º–µ–Ω—å—à–µ
    filtered_data = {key: [] for key in data.keys()}

    for i in range(len(data["text"])):
        if len(data["text"][i].strip()) > min_text_length:
            for key in data.keys():
                filtered_data[key].append(data[key][i])

    return filtered_data


def relative_luminance(rgb):
    def channel_lum(c):
        c = c / 255.0
        return c / 12.92 if c <= 0.03928 else ((c + 0.055) / 1.055) ** 2.4

    r, g, b = rgb
    return 0.2126 * channel_lum(r) + 0.7152 * channel_lum(g) + 0.0722 * channel_lum(b)


def contrast_ratio(lum1, lum2):
    L1, L2 = max(lum1, lum2), min(lum1, lum2)
    return (L1 + 0.05) / (L2 + 0.05)


def check_text_contrast(img_array: np.ndarray, ocr_data):
    warnings = []

    for i in range(len(ocr_data["text"])):
        confidence_rate = 60

        try:
            conf = int(ocr_data["conf"][i])
        except ValueError:
            continue

        text = ocr_data["text"][i].strip()

        if conf >= confidence_rate and text:
            x, y, w, h = ocr_data["left"][i], ocr_data["top"][i], ocr_data["width"][i], ocr_data["height"][i]
            region = img_array[y:y + h, x:x + w]

            if region.size == 0:
                continue

            if region.shape[2] == 4:  # remove alpha
                region = region[:, :, :3]

            pixels = region.reshape(-1, 3)

            try:
                kmeans = KMeans(n_clusters=2, n_init="auto", random_state=0).fit(pixels)
                cluster_centers = kmeans.cluster_centers_
                labels = kmeans.labels_

                counts = np.bincount(labels)
                text_rgb = cluster_centers[np.argmin(counts)]  # –º–µ–Ω—å—à–∞—è –≥—Ä—É–ø–ø–∞ ‚Äî –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ —Ç–µ–∫—Å—Ç
                bg_rgb = cluster_centers[np.argmax(counts)]  # –±–æ–ª—å—à–∞—è –≥—Ä—É–ø–ø–∞ ‚Äî —Ñ–æ–Ω

                text_lum = relative_luminance(text_rgb)
                bg_lum = relative_luminance(bg_rgb)

                contrast = contrast_ratio(text_lum, bg_lum)

                if contrast < 4.5:
                    warnings.append(
                        f"‚ö†Ô∏è –ù–∏–∑–∫–∏–π –∫–æ–Ω—Ç—Ä–∞—Å—Ç —Ç–µ–∫—Å—Ç–∞ '{text}': {contrast:.2f} (–º–µ–Ω–µ–µ 4.5)"
                    )
            except Exception as e:
                print(f"KMeans error: {e}")
                continue

    return warnings


def analyze_clutter(ocr_data, image_size):
    width, height = image_size
    image_area = width * height
    num_elements = 0
    total_text_area = 0
    boxes = []

    for i in range(len(ocr_data['text'])):
        text = ocr_data['text'][i]
        if not text.strip():
            continue
        w = ocr_data['width'][i]
        h = ocr_data['height'][i]
        area = w * h
        total_text_area += area
        num_elements += 1
        boxes.append((ocr_data['left'][i], ocr_data['top'][i], w, h))

    text_density = num_elements / image_area
    area_ratio = total_text_area / image_area

    # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É –±–ª–æ–∫–∞–º–∏
    def avg_distance(boxes):

        if len(boxes) < 2:
            return 0
        distances = []

        for i in range(len(boxes)):
            for j in range(i + 1, len(boxes)):
                x1, y1, _, _ = boxes[i]
                x2, y2, _, _ = boxes[j]
                dist = ((x2 - x1) ** 2 + (y2 - y1) ** 2) ** 0.5
                distances.append(dist)
        return sum(distances) / len(distances)

    cluster_score = avg_distance(boxes) / (image_size[0] + image_size[1])

    # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç–∏
    clutter_score = 0

    if num_elements > 25:
        clutter_score += 1
    elif num_elements > 50:
        clutter_score += 2

    if area_ratio > 0.05:
        clutter_score += 1

    if text_density > 0.00025:
        clutter_score += 1

    if cluster_score < 0.1:
        clutter_score += 1

    is_cluttered = clutter_score >= 2

    return {
        "num_elements": num_elements,
        "area_ratio": round(area_ratio, 3),
        "text_density": round(text_density, 6),
        "cluster_score": round(cluster_score, 3),
        "is_cluttered": is_cluttered
    }


# ========== –¢–µ–∫—Å—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π ==========
good_text = "#### ‚úÖ –í–∞—à –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º UX"

# ========== STREAMLIT UI ==========
st.set_page_config(page_title="UX/UI —ç–∫—Å–ø–µ—Ä—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞", layout="centered")
st.title("üîç UX/UI —ç–∫—Å–ø–µ—Ä—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞")

uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–∫—Ä–∏–Ω—à–æ—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ (PNG –∏–ª–∏ JPG)", type=["png", "jpg", "jpeg"])

if uploaded_file:
    image = Image.open(uploaded_file)
    st.image(image, caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")

    st.divider()

    # OCR + —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
    st.header("üìÑ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç—å")
    ocr_data = perform_ocr_analysis(image)

    img_array = np.array(image)
    contrast_warnings = check_text_contrast(img_array, ocr_data)

    if not contrast_warnings:
        st.success("‚úÖ –¢–µ–∫—Å—Ç –ø—Ä–æ—à–µ–ª –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç—å")
    else:
        for w in contrast_warnings:
            st.warning(w)

    st.divider()

    # –ü–µ—Ä–µ–≥—Ä—É–∑–∫–∞ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
    clutter_info = analyze_clutter(ocr_data, image.size)
    st.subheader("üìä –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞")
    st.write(f"–≠–ª–µ–º–µ–Ω—Ç–æ–≤ —Ç–µ–∫—Å—Ç–∞: {clutter_info['num_elements']}")
    st.write(f"–ü–ª–æ—â–∞–¥—å —Ç–µ–∫—Å—Ç–∞ –∫ –æ–±—â–µ–π: {clutter_info['area_ratio']}")
    st.write(f"–ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞: {clutter_info['text_density']}")
    st.write(f"–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è: {clutter_info['cluster_score']}")
    if clutter_info["is_cluttered"]:
        st.warning("‚ö† **–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω**")
    else:
        st.success("‚úÖ –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω")

    st.divider()

    # –û–±—â–∏–µ –≤—ã–≤–æ–¥—ã
    st.header("–û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")

    if contrast_warnings:
        with st.chat_message("user"):
            st.markdown("### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç–∏")
            st.markdown("–ò–∑—É—á–∏—Ç–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã WCAG –∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–ª–∞–≥–∏–Ω—ã –≤ Figma –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
            st.markdown("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø—Ä–∏—â—É—Ä–∏—Ç—å –≥–ª–∞–∑–∞ –∏ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ç–µ–∫—Å—Ç. –ï—Å–ª–∏ –æ–Ω –ø–ª–æ—Ö–æ —á–∏—Ç–∞–µ—Ç—Å—è, —Å–¥–µ–ª–∞–π—Ç–µ –µ–≥–æ "
                        "–∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–µ–µ –∏–ª–∏ —É–≤–µ–ª–∏—á—å—Ç–µ —Ä–∞–∑–º–µ—Ä")

    if clutter_info["is_cluttered"]:
        with st.chat_message("user"):
            st.markdown("### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞")
            st.markdown("#### –û–ø—Ä–µ–¥–µ–ª–∏—Ç–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã")
            st.markdown("üí° –ó–∞–¥–∞–π —Å–µ–±–µ –≤–æ–ø—Ä–æ—Å: –∫–∞–∫—É—é –∑–∞–¥–∞—á—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–æ–ª–∂–µ–Ω —Ä–µ—à–∏—Ç—å –Ω–∞ —ç—Ç–æ–º —ç–∫—Ä–∞–Ω–µ –≤ –ø–µ—Ä–≤—É—é –æ—á–µ—Ä–µ–¥—å?")
            st.markdown("‚ùó –°–æ—Ö—Ä–∞–Ω–∏ —Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥–∞—é—Ç –≤—ã–ø–æ–ª–Ω–∏—Ç—å —ç—Ç—É –∑–∞–¥–∞—á—É.")
            st.markdown("#### –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—É—Å—Ç–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –æ—Å–æ–∑–Ω–∞–Ω–Ω–æ")
            st.markdown("üßò –ù–µ –±–æ–π—Å—è –ø—É—Å—Ç–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ ‚Äî –æ–Ω–æ –ø–æ–º–æ–≥–∞–µ—Ç –≥–ª–∞–∑—É –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è.")
            st.markdown("#### –ú–∏–Ω–∏–º–∏–∑–∏—Ä—É–π—Ç–µ —Ç–µ–∫—Å—Ç")
            st.markdown("‚úÇÔ∏è –£–±–∏—Ä–∞–π –≤–≤–æ–¥–Ω—ã–µ —Å–ª–æ–≤–∞ –∏ ¬´–≤–æ–¥—É¬ª. –ü—Ä–∏–º–µ—Ä: –≤–º–µ—Å—Ç–æ ¬´–ß—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å, –Ω–∞–∂–º–∏—Ç–µ –Ω–∞ —ç—Ç—É –∫–Ω–æ–ø–∫—É¬ª ‚Üí "
                        "¬´–ù–∞—á–∞—Ç—å¬ª.")
            st.markdown("#### –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –∞–∫—Ü–µ–Ω—Ç—ã –∏ —Ü–≤–µ—Ç–∞ —Å —É–º–æ–º")
            st.markdown("üé® –û–≥—Ä–∞–Ω–∏—á—å –ø–∞–ª–∏—Ç—Ä—É –¥–æ 2‚Äì3 –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ü–≤–µ—Ç–æ–≤ + –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π —Ñ–æ–Ω.")
            st.markdown("üö¶ –¶–≤–µ—Ç –ø–æ–º–æ–≥–∞–µ—Ç –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è: –≤—ã–¥–µ–ª–∏ –≥–ª–∞–≤–Ω–æ–µ, –∞ –≤—Ç–æ—Ä–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–µ ‚Äî –ø—Ä–∏–≥–ª—É—à–∏.")
            st.markdown("#### –°–æ–∫—Ä–∞—Ç–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–Ω–æ–ø–æ–∫ –∏ –¥–µ–π—Å—Ç–≤–∏–π")
            st.markdown("üëá –û–±—ä–µ–¥–∏–Ω–∏—Ç–µ –ø–æ—Ö–æ–∂–∏–µ –¥–µ–π—Å—Ç–≤–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, ¬´–°–æ—Ö—Ä–∞–Ω–∏—Ç—å¬ª –∏ ¬´–ì–æ—Ç–æ–≤–æ¬ª).")
            st.markdown("üì§ –£–±–µ—Ä–∏—Ç–µ —Ä–µ–¥–∫–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∫–Ω–æ–ø–∫–∏ –∏–ª–∏ –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç–µ –∏—Ö –≤ –º–µ–Ω—é ¬´–µ—â—ë¬ª.")

    if not (contrast_warnings or clutter_info["is_cluttered"]):
        st.success(good_text)
